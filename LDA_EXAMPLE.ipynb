{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deef940e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mcsv\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mlda\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lda'"
     ]
    }
   ],
   "source": [
    "import os, csv, nltk, lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef859626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                             Labels\n",
      "0      1  White Black Standing Black-and-white Monochrom...\n",
      "1      2  Herd Sheep Sheep Sky Shepherd Pasture Grasslan...\n",
      "2      3                         Computed tomography Circle\n",
      "3      4  Sky Horizon Water Ocean Cloud Sea Daytime Atmo...\n",
      "4      5  Mountainous landforms Mountain Mountain range ...\n",
      "..   ...                                                ...\n",
      "395  396  Formation Nature Cave Underground lake Sea cav...\n",
      "396  397  Sky Grassland Natural landscape Field Plain Na...\n",
      "397  398  Light Yellow Sky Room Sunlight Photography Tin...\n",
      "398  399  People Black-and-white Monochrome Monochrome p...\n",
      "399  400  Atmospheric phenomenon Light Sky Darkness Atmo...\n",
      "\n",
      "[400 rows x 2 columns]\n",
      "Number of rows with any of the empty columns:\n",
      "0\n",
      "provide the column name for id: id\n",
      "provide the column name for text: Labels\n",
      "Provide the number of latent topics: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mihir\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3.6\n",
    "#Install LDA library if not already installed\n",
    "# pip3.6 install --user lda\n",
    "# the input file is natgeo_labels_2020.xlsx\n",
    "# there are two output files: topic_word_dist.xlsx and document_topic_dist.xlsx\n",
    "# the script prompts for the name of the columns -- Restaurant_name and Restaurant_review in the yelp_reviews.xslx file\n",
    "import os, csv, nltk  #, lda\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import PunktSentenceTokenizer, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.tokenize import PunktSentenceTokenizer,RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "reviews_df=pd.read_excel(\"data/natgeo_labels_2020.xlsx\", engine='openpyxl')\n",
    "\n",
    "print(reviews_df)\n",
    "\n",
    "#checking for nulls if present any\n",
    "print(\"Number of rows with any of the empty columns:\")\n",
    "print(reviews_df.isnull().sum().sum())\n",
    "reviews_df=reviews_df.dropna()\n",
    "\n",
    "restaurant_name = input('provide the column name for id: ')\n",
    "restaurant_review = input('provide the column name for text: ')\n",
    "ntopics= input('Provide the number of latent topics: ');\n",
    "\n",
    "\n",
    "\n",
    "word_tokenizer=RegexpTokenizer(r'\\w+')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stopwords_nltk=set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def tokenize_text(version_desc):\n",
    "    lowercase=version_desc.lower()\n",
    "    text = wordnet_lemmatizer.lemmatize(lowercase)\n",
    "    tokens = word_tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "vec_words = CountVectorizer(tokenizer=tokenize_text,stop_words=stopwords_nltk,decode_error='ignore')\n",
    "total_features_words = vec_words.fit_transform(reviews_df[restaurant_review])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "568c0351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 885)\t2\n",
      "  (0, 101)\t2\n",
      "  (0, 761)\t1\n",
      "  (0, 530)\t2\n",
      "  (0, 425)\t1\n",
      "  (0, 719)\t1\n",
      "  (0, 612)\t2\n",
      "  (0, 722)\t1\n",
      "  (1, 407)\t1\n",
      "  (1, 714)\t2\n",
      "  (1, 734)\t1\n",
      "  (1, 716)\t1\n",
      "  (1, 597)\t1\n",
      "  (1, 377)\t1\n",
      "  (1, 408)\t1\n",
      "  (1, 185)\t1\n",
      "  (1, 376)\t1\n",
      "  (2, 202)\t1\n",
      "  (2, 818)\t1\n",
      "  (2, 174)\t1\n",
      "  (3, 734)\t1\n",
      "  (3, 185)\t1\n",
      "  (3, 417)\t1\n",
      "  (3, 875)\t1\n",
      "  (3, 571)\t1\n",
      "  :\t:\n",
      "  (397, 814)\t1\n",
      "  (397, 711)\t1\n",
      "  (397, 328)\t1\n",
      "  (397, 256)\t1\n",
      "  (398, 885)\t1\n",
      "  (398, 101)\t1\n",
      "  (398, 530)\t2\n",
      "  (398, 425)\t1\n",
      "  (398, 612)\t3\n",
      "  (398, 603)\t1\n",
      "  (398, 770)\t1\n",
      "  (398, 777)\t1\n",
      "  (398, 739)\t1\n",
      "  (398, 728)\t1\n",
      "  (399, 734)\t1\n",
      "  (399, 54)\t1\n",
      "  (399, 480)\t1\n",
      "  (399, 481)\t1\n",
      "  (399, 565)\t1\n",
      "  (399, 234)\t1\n",
      "  (399, 55)\t1\n",
      "  (399, 610)\t1\n",
      "  (399, 740)\t1\n",
      "  (399, 521)\t1\n",
      "  (399, 335)\t1\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
